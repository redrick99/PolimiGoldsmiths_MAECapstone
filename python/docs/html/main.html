<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>main API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>main</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import modules.default_parameters as dp
import os
import numpy as np
from multiprocessing import Process, Queue, Event
from queue import Full, Empty
from modules.setup import SetupHandler
from modules.audioprocessing import LFAudioInputHandler, HFAudioInputHandler
from modules.audio_producer import AudioProducer
from modules.utilities import *
from modules.custom_exceptions import *


def stop_execution(lf_queue: Queue, hf_queue: Queue, streams: list):
    &#34;&#34;&#34;Stops all concurrent worker processes. It does so by putting a number of `None` objects inside the
    multiprocessing `Queues`.

    **Args:**

    `lf_queue`: Common queue for all Low Level Features workers.

    `hf_queue`: Common queue for all High Level Features workers.

    `streams`: All currently open streams of audio.
    &#34;&#34;&#34;
    for _ in range(dp.CPU_PARAMETERS[&#39;numLfCores&#39;]):
        lf_queue.put(None)  # When the worker reads `None` from the queue it breaks its loop
    for _ in range(dp.CPU_PARAMETERS[&#39;numHfCores&#39;]):
        hf_queue.put(None)
    for s in streams:
        if s:
            s.stop_stream()
            s.close()


def audio_producer(audio_producer_object: AudioProducer, control_event, lf_queue: Queue, hf_queue: Queue, parameters: dict):
    &#34;&#34;&#34;Produces audio for the worker processes. Each chunk of audio read from the audio source is sent to the low-level
    feature processes to extract low-level features. Audio chunks are summed to a total length of n seconds before
    being sent to the high-level feature processes.

    **Args:**

    `audio_producer_object`: Object of the super-class AudioProducer used to produce audio.

    `control_event`: Event used to check if the program&#39;s execution has to be stopped.

    `lf_queue`: Common queue for LLF workers used to send the chunks of audio to process.

    `hf_queue`: Common queue for HLF workers used to send the chunks of audio to process.

    `parameters`: Dictionary containing audio processing parameters used to produce audio.
    &#34;&#34;&#34;
    sh = SetupHandler.get_instance()
    sh.set_audio_parameters(parameters)
    in_stream, out_stream = sh.get_audio_streams()
    data_type = parameters[&#39;npFormat&#39;]
    hf_number_of_samples = parameters[&#39;hfNumberOfSamples&#39;]
    hf_data = np.array([], dtype=data_type)

    print_success(&#34;Started audio producer process&#34;)

    while True:
        try:
            if control_event.is_set():
                stop_execution(lf_queue, hf_queue, [in_stream, out_stream])
                return

            audio_chunk = audio_producer_object.get_next_chunk(in_stream, out_stream)
            audio_chunk_np = np.array(audio_chunk, dtype=data_type, copy=True)

            lf_queue.put_nowait(audio_chunk)
            audio_chunk_np = audio_chunk_np.sum(axis=0)/float(len(audio_chunk))
            hf_data = np.concatenate((hf_data, audio_chunk_np), dtype=data_type)

            if len(hf_data) &gt;= hf_number_of_samples:
                cut_data = hf_data[hf_number_of_samples:len(hf_data)]
                hf_data = hf_data[0:hf_number_of_samples]
                hf_queue.put(np.copy(hf_data))
                hf_data = np.array(cut_data, dtype=data_type)

        except Full:
            print_warning(&#34;Queue is full&#34;)
            continue
        except FinishedSongException as e:
            print_info(&#34;Song is finished&#34;)
            stop_execution(lf_queue, hf_queue, [in_stream, out_stream])
            return
        except AudioProducingException as e:
            print_error(e)
        except Exception as e:
            print_error(&#34;Something bad happened while producing audio&#34;)
            print_dbg(e)


def lf_audio_consumer(lf_queue: Queue, settings_queue: Queue, parameters: dict):
    &#34;&#34;&#34;Processes low-level features from audio chunks given from the `audio_producer` process.

    **Args:**

    `lf_queue`: Queue where audio chunks to process are sent by the audio_producer process.

    `settings_queue`: Queue where audio settings (coming from osc messages) are sent - used to change settings
    of the LLF handlers.

    `parameters`: Dictionary containing audio processing parameters used to produce audio.
    &#34;&#34;&#34;
    lf_audio_input_handlers = []
    channels = parameters[&#39;channels&#39;]
    instruments = parameters[&#39;instruments&#39;]
    for i in range(channels):
        lf_audio_input_handlers.append(LFAudioInputHandler(parameters, i, instruments[i]))
    
    print_success(&#34;Started LF consumer process&#34;)
    while True:
        data = lf_queue.get()
        if data is None:
            print_info(&#34;Shutting down LF process...&#34;)
            break

        try:
            channel, settings = settings_queue.get_nowait()
            for handler in lf_audio_input_handlers:
                if handler.channel == channel:
                    handler.handle_settings(settings)
                    break
        except Empty:
            pass

        try:
            for i in range(len(lf_audio_input_handlers)):
                lf_audio_input_handlers[i].process(data[i])
        except Exception as e:
            print_error(&#34;Something bad happened while processing audio (LLF)&#34;)
            print_dbg(e)


def hf_audio_consumer(hf_queue: Queue, parameters: dict):
    &#34;&#34;&#34;Processes high-level features from audio chunks given from the `audio_producer` process.

    **Args:**

    `hf_queue`: Queue where audio chunks to process are sent by the `audio_producer` process.

    `parameters`: Dictionary containing audio processing parameters used to produce audio.
    &#34;&#34;&#34;
    hf_audio_input_handler = HFAudioInputHandler(parameters, 0, Instruments.DEFAULT)

    print_success(&#34;Started HF consumer process&#34;)
    while True:
        data = hf_queue.get()
        if data is None:
            print_info(&#34;Shutting down HF process...&#34;)
            break
        try:
            hf_audio_input_handler.process(data)
        except Exception as e:
            print_error(&#34;Something bad happened while processing audio (HLF)&#34;)
            print_dbg(e)


if __name__ == &#34;__main__&#34;:
    sh = SetupHandler.get_instance()  # General setup of the application is handled by the SetupHandler singleton
    sh.set_main_path(os.path.dirname(__file__))
    parameters = sh.setup()
    audio_producer_object = sh.get_audio_producer()

    control_event = Event()  # Initializes multiprocessing objects
    cpu_parameters = dp.CPU_PARAMETERS
    lf_queue = Queue()
    hf_queue = Queue()
    settings_queue = Queue()

    processes = []  # Initializes processes based on the number of wanted parallel workers
    for _ in range(cpu_parameters[&#39;numLfCores&#39;]):
        processes.append(Process(target=lf_audio_consumer, args=(
            lf_queue,
            settings_queue,
            parameters,
        )))
    for _ in range(cpu_parameters[&#39;numHfCores&#39;]):
        processes.append(Process(target=hf_audio_consumer, args=(
            hf_queue,
            parameters,
        )))

    processes.append(Process(target=audio_producer, args=(
        audio_producer_object,
        control_event,
        lf_queue,
        hf_queue,
        parameters,
    )))

    for p in processes:  # Starts processes
        p.start()

    for p in processes:  # Waits for processes to end
        p.join()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="main.audio_producer"><code class="name flex">
<span>def <span class="ident">audio_producer</span></span>(<span>audio_producer_object: modules.audio_producer.AudioProducer, control_event, lf_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x10331e0a0>>, hf_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x10331e0a0>>, parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Produces audio for the worker processes. Each chunk of audio read from the audio source is sent to the low-level
feature processes to extract low-level features. Audio chunks are summed to a total length of n seconds before
being sent to the high-level feature processes.</p>
<p><strong>Args:</strong></p>
<p><code>audio_producer_object</code>: Object of the super-class AudioProducer used to produce audio.</p>
<p><code>control_event</code>: Event used to check if the program's execution has to be stopped.</p>
<p><code>lf_queue</code>: Common queue for LLF workers used to send the chunks of audio to process.</p>
<p><code>hf_queue</code>: Common queue for HLF workers used to send the chunks of audio to process.</p>
<p><code>parameters</code>: Dictionary containing audio processing parameters used to produce audio.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def audio_producer(audio_producer_object: AudioProducer, control_event, lf_queue: Queue, hf_queue: Queue, parameters: dict):
    &#34;&#34;&#34;Produces audio for the worker processes. Each chunk of audio read from the audio source is sent to the low-level
    feature processes to extract low-level features. Audio chunks are summed to a total length of n seconds before
    being sent to the high-level feature processes.

    **Args:**

    `audio_producer_object`: Object of the super-class AudioProducer used to produce audio.

    `control_event`: Event used to check if the program&#39;s execution has to be stopped.

    `lf_queue`: Common queue for LLF workers used to send the chunks of audio to process.

    `hf_queue`: Common queue for HLF workers used to send the chunks of audio to process.

    `parameters`: Dictionary containing audio processing parameters used to produce audio.
    &#34;&#34;&#34;
    sh = SetupHandler.get_instance()
    sh.set_audio_parameters(parameters)
    in_stream, out_stream = sh.get_audio_streams()
    data_type = parameters[&#39;npFormat&#39;]
    hf_number_of_samples = parameters[&#39;hfNumberOfSamples&#39;]
    hf_data = np.array([], dtype=data_type)

    print_success(&#34;Started audio producer process&#34;)

    while True:
        try:
            if control_event.is_set():
                stop_execution(lf_queue, hf_queue, [in_stream, out_stream])
                return

            audio_chunk = audio_producer_object.get_next_chunk(in_stream, out_stream)
            audio_chunk_np = np.array(audio_chunk, dtype=data_type, copy=True)

            lf_queue.put_nowait(audio_chunk)
            audio_chunk_np = audio_chunk_np.sum(axis=0)/float(len(audio_chunk))
            hf_data = np.concatenate((hf_data, audio_chunk_np), dtype=data_type)

            if len(hf_data) &gt;= hf_number_of_samples:
                cut_data = hf_data[hf_number_of_samples:len(hf_data)]
                hf_data = hf_data[0:hf_number_of_samples]
                hf_queue.put(np.copy(hf_data))
                hf_data = np.array(cut_data, dtype=data_type)

        except Full:
            print_warning(&#34;Queue is full&#34;)
            continue
        except FinishedSongException as e:
            print_info(&#34;Song is finished&#34;)
            stop_execution(lf_queue, hf_queue, [in_stream, out_stream])
            return
        except AudioProducingException as e:
            print_error(e)
        except Exception as e:
            print_error(&#34;Something bad happened while producing audio&#34;)
            print_dbg(e)</code></pre>
</details>
</dd>
<dt id="main.hf_audio_consumer"><code class="name flex">
<span>def <span class="ident">hf_audio_consumer</span></span>(<span>hf_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x10331e0a0>>, parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Processes high-level features from audio chunks given from the <code><a title="main.audio_producer" href="#main.audio_producer">audio_producer()</a></code> process.</p>
<p><strong>Args:</strong></p>
<p><code>hf_queue</code>: Queue where audio chunks to process are sent by the <code><a title="main.audio_producer" href="#main.audio_producer">audio_producer()</a></code> process.</p>
<p><code>parameters</code>: Dictionary containing audio processing parameters used to produce audio.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hf_audio_consumer(hf_queue: Queue, parameters: dict):
    &#34;&#34;&#34;Processes high-level features from audio chunks given from the `audio_producer` process.

    **Args:**

    `hf_queue`: Queue where audio chunks to process are sent by the `audio_producer` process.

    `parameters`: Dictionary containing audio processing parameters used to produce audio.
    &#34;&#34;&#34;
    hf_audio_input_handler = HFAudioInputHandler(parameters, 0, Instruments.DEFAULT)

    print_success(&#34;Started HF consumer process&#34;)
    while True:
        data = hf_queue.get()
        if data is None:
            print_info(&#34;Shutting down HF process...&#34;)
            break
        try:
            hf_audio_input_handler.process(data)
        except Exception as e:
            print_error(&#34;Something bad happened while processing audio (HLF)&#34;)
            print_dbg(e)</code></pre>
</details>
</dd>
<dt id="main.lf_audio_consumer"><code class="name flex">
<span>def <span class="ident">lf_audio_consumer</span></span>(<span>lf_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x10331e0a0>>, settings_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x10331e0a0>>, parameters: dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Processes low-level features from audio chunks given from the <code><a title="main.audio_producer" href="#main.audio_producer">audio_producer()</a></code> process.</p>
<p><strong>Args:</strong></p>
<p><code>lf_queue</code>: Queue where audio chunks to process are sent by the audio_producer process.</p>
<p><code>settings_queue</code>: Queue where audio settings (coming from osc messages) are sent - used to change settings
of the LLF handlers.</p>
<p><code>parameters</code>: Dictionary containing audio processing parameters used to produce audio.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lf_audio_consumer(lf_queue: Queue, settings_queue: Queue, parameters: dict):
    &#34;&#34;&#34;Processes low-level features from audio chunks given from the `audio_producer` process.

    **Args:**

    `lf_queue`: Queue where audio chunks to process are sent by the audio_producer process.

    `settings_queue`: Queue where audio settings (coming from osc messages) are sent - used to change settings
    of the LLF handlers.

    `parameters`: Dictionary containing audio processing parameters used to produce audio.
    &#34;&#34;&#34;
    lf_audio_input_handlers = []
    channels = parameters[&#39;channels&#39;]
    instruments = parameters[&#39;instruments&#39;]
    for i in range(channels):
        lf_audio_input_handlers.append(LFAudioInputHandler(parameters, i, instruments[i]))
    
    print_success(&#34;Started LF consumer process&#34;)
    while True:
        data = lf_queue.get()
        if data is None:
            print_info(&#34;Shutting down LF process...&#34;)
            break

        try:
            channel, settings = settings_queue.get_nowait()
            for handler in lf_audio_input_handlers:
                if handler.channel == channel:
                    handler.handle_settings(settings)
                    break
        except Empty:
            pass

        try:
            for i in range(len(lf_audio_input_handlers)):
                lf_audio_input_handlers[i].process(data[i])
        except Exception as e:
            print_error(&#34;Something bad happened while processing audio (LLF)&#34;)
            print_dbg(e)</code></pre>
</details>
</dd>
<dt id="main.stop_execution"><code class="name flex">
<span>def <span class="ident">stop_execution</span></span>(<span>lf_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x10331e0a0>>, hf_queue: <bound method BaseContext.Queue of <multiprocessing.context.DefaultContext object at 0x10331e0a0>>, streams: list)</span>
</code></dt>
<dd>
<div class="desc"><p>Stops all concurrent worker processes. It does so by putting a number of <code>None</code> objects inside the
multiprocessing <code>Queues</code>.</p>
<p><strong>Args:</strong></p>
<p><code>lf_queue</code>: Common queue for all Low Level Features workers.</p>
<p><code>hf_queue</code>: Common queue for all High Level Features workers.</p>
<p><code>streams</code>: All currently open streams of audio.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stop_execution(lf_queue: Queue, hf_queue: Queue, streams: list):
    &#34;&#34;&#34;Stops all concurrent worker processes. It does so by putting a number of `None` objects inside the
    multiprocessing `Queues`.

    **Args:**

    `lf_queue`: Common queue for all Low Level Features workers.

    `hf_queue`: Common queue for all High Level Features workers.

    `streams`: All currently open streams of audio.
    &#34;&#34;&#34;
    for _ in range(dp.CPU_PARAMETERS[&#39;numLfCores&#39;]):
        lf_queue.put(None)  # When the worker reads `None` from the queue it breaks its loop
    for _ in range(dp.CPU_PARAMETERS[&#39;numHfCores&#39;]):
        hf_queue.put(None)
    for s in streams:
        if s:
            s.stop_stream()
            s.close()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="main.audio_producer" href="#main.audio_producer">audio_producer</a></code></li>
<li><code><a title="main.hf_audio_consumer" href="#main.hf_audio_consumer">hf_audio_consumer</a></code></li>
<li><code><a title="main.lf_audio_consumer" href="#main.lf_audio_consumer">lf_audio_consumer</a></code></li>
<li><code><a title="main.stop_execution" href="#main.stop_execution">stop_execution</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>